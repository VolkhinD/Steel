{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1MnCyjKdUhq8ZJB0EGadErNBk6YhXN4H0",
      "authorship_tag": "ABX9TyOE5NkQp85eK6rhTwFWMndy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VolkhinD/Steel/blob/main/Ultralytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ6JOsNzC4JR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install ultralytics\n",
        "!pip install PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow # since cv2.imshow collaps Colab session\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "import torch\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "\n",
        "sns.set_palette('BrBG_r')"
      ],
      "metadata": {
        "id": "uudyfCOpDIkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (256, 1600)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "9JK94QRATuYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Play with YOLO"
      ],
      "metadata": {
        "id": "Wm5vkm9Zp41O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = '/content/drive/MyDrive/Data/IMG_1541.jpg'\n",
        "img2 = '/content/drive/MyDrive/Data/IMG_1476.jpg'\n",
        "img3 = '/content/pr_cat.jpg'\n",
        "im1 = cv2.imread(img1)"
      ],
      "metadata": {
        "id": "s2c2_zS9Dsjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_model = YOLO('yolov8m-seg.pt')"
      ],
      "metadata": {
        "id": "2SobuZSyYAvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = seg_model.predict(im1)\n",
        "result = results[0]\n",
        "masks = result.masks\n",
        "len(masks)"
      ],
      "metadata": {
        "id": "owQgxvHlb0nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask1 = masks[0].data.cpu()\n",
        "mask2 = masks[1].data.cpu()"
      ],
      "metadata": {
        "id": "CyIynWpHcOGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3)\n",
        "ax[0].imshow(im1)\n",
        "ax[1].imshow(mask1.permute(1, 2, 0))\n",
        "ax[2].imshow(mask2.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "X9ZI_uM6GGll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create masks and polygons"
      ],
      "metadata": {
        "id": "WuI_8G8Vp-A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Data/Steel/train.csv')\n"
      ],
      "metadata": {
        "id": "r7LP9BvgqCAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.ClassId = data.ClassId.map({1: 0, 2: 1, 3: 2, 4: 3})\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ghwzSvLzv1y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_2D_mask(idx, imgshape=IMG_SIZE):\n",
        "\n",
        "  \"\"\"Creates mask for all types of defects\"\"\"\n",
        "\n",
        "  width = imgshape[0]\n",
        "  height= imgshape[1]\n",
        "  img_name = data.iloc[idx].ImageId\n",
        "  all_img = data.groupby('ImageId').get_group(img_name)\n",
        "\n",
        "  mask = np.zeros(width*height).astype(np.uint8)\n",
        "\n",
        "  if all_img.EncodedPixels.isnull().any(): # any because I plan to add img with no defects so they have only 'ImageId'\n",
        "    return mask.reshape(width, height)\n",
        "\n",
        "  for class_id, rle in zip(all_img.ClassId.to_numpy(), all_img.EncodedPixels.to_numpy()):\n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = class_id\n",
        "\n",
        "\n",
        "  return np.flipud(np.rot90(mask.reshape(height, width), k=1))"
      ],
      "metadata": {
        "id": "49u8nnt2eKvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Copied from Kaggle\"\"\"\n",
        "def rle2mask(rle, imgshape=IMG_SIZE):\n",
        "\n",
        "  \"\"\" Creates mask for only one type of deffect \"\"\"\n",
        "\n",
        "  width = imgshape[0]\n",
        "  height= imgshape[1]\n",
        "\n",
        "  mask = np.zeros( width*height ).astype(np.uint8)\n",
        "\n",
        "  array = np.asarray([int(x) for x in rle.split()])\n",
        "  starts = array[0::2]\n",
        "  lengths = array[1::2]\n",
        "\n",
        "  for index, start in enumerate(starts):\n",
        "      mask[int(start):int(start+lengths[index])] = 1\n",
        "\n",
        "\n",
        "  return np.flipud(np.rot90( mask.reshape(height, width), k=1))"
      ],
      "metadata": {
        "id": "8KFdWjI1wkS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Data/Steel/data/train/images/'\n",
        "fn = data['ImageId'].iloc[2]\n",
        "img = cv2.imread(path + fn)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "HXRfs7Qsux99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask1 = rle_2D_mask(2)\n",
        "plt.imshow(mask1)"
      ],
      "metadata": {
        "id": "3g1ItcQ9rt04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RLE to Polygon"
      ],
      "metadata": {
        "id": "6OodKWUkrQ6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn = data['ImageId'].iloc[2]\n",
        "img = cv2.imread(path + fn)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "contours, heirarchy = cv2.findContours(mask1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#draw the obtained contour lines(or the set of coordinates forming a line) on the original image\n",
        "cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
        "#show the image\n",
        "cv2_imshow(img)\n"
      ],
      "metadata": {
        "id": "v_xBQKe2uIfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"There are {len(contours)} objects on this example mask\")\n",
        "print(f\"Image shape {img.shape}\")"
      ],
      "metadata": {
        "id": "yEsjOlFm5BwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = open(\"/content/drive/MyDrive/Data/Steel/data/train/labels/test.txt\", \"a\")\n",
        "# for i in range(10):\n",
        "#   f.write(str(i) + '\\t')\n",
        "# f.write('\\n')\n",
        "# f.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "X8IMcZKB18uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Ready Images with [this Artical](https://dev.to/andreygermanov/how-to-implement-instance-segmentation-using-yolov8-neural-network-3if9#get_started)"
      ],
      "metadata": {
        "id": "Wq7r9IQ2gQ07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Created a folder for dataset and two subfolders in it: \"images\" and \"labels\".\n",
        "\n",
        "2. Put the images to the \"images\" subfolder.\n",
        "\n",
        "3. For each image, create an annotation text file in the \"labels\" subfolder. Annotation text files should have the same names as image files and the \".txt\" extensions. In annotation file you should add records about each object, that exist on the appropriate image in the following format:\n",
        "\n",
        "    {object_class_id} {polygon}\n",
        "\n",
        "    **object_class_id** is a label of object class, there are 4 classes in dataset\n",
        "\n",
        "    **polygon** is a coordinates of bounding polygon for this object in the following format: x1 y1 x2 y2 ...\n",
        "\n",
        "    Coordinates should be normalized to fit in a range from 0 to 1. To calculate them, I need to use the following formulas:\n",
        "\n",
        "    x = x/image_width\n",
        "    y = y/image_height\n",
        "\n",
        "4. Finally, I need to create a dataset descriptor YAML-file, that points to created datasets and describes the object classes in them.\n",
        "\n"
      ],
      "metadata": {
        "id": "dmIJzOZDglG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split to Train and Validation"
      ],
      "metadata": {
        "id": "o4j7zZ05Zfi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Done this ones \"\"\"\n",
        "\n",
        "splitter = GroupShuffleSplit(test_size=.15, n_splits=2, random_state = 7)\n",
        "split = splitter.split(data, groups=data.ImageId)\n",
        "train_inds, test_inds = next(split)\n",
        "\n",
        "# train = data.iloc[train_inds]\n",
        "# test = data.iloc[test_inds]\n",
        "\n",
        "print(f\"Length of train set is {len(train_inds)}\")\n",
        "print(f\"Length of test set is {len(test_inds)}\")\n"
      ],
      "metadata": {
        "id": "j7lMVhohGjsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_to_fol(source, destination, indexes):\n",
        "  absent_files = []\n",
        "  for idx in indexes:\n",
        "    img_name = data.ImageId.iloc[idx]\n",
        "    src_path = os.path.join(source, img_name)\n",
        "    dst_path = os.path.join(destination, img_name)\n",
        "    try:\n",
        "      shutil.move(src_path, dst_path)\n",
        "    except:\n",
        "      absent_files.append(img_name)\n",
        "\n",
        "  return absent_files"
      ],
      "metadata": {
        "id": "eWlfoTNZPKmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source = '/content/drive/MyDrive/Data/Steel/all/images'\n",
        "# destination_train = '/content/drive/MyDrive/Data/Steel/data/train/images'\n",
        "# destination_val = '/content/drive/MyDrive/Data/Steel/data/val/images'\n",
        "# train_absent = transfer_to_fol(source, destination_train, train_inds)\n",
        "# test_absent = transfer_to_fol(source, destination_val, test_inds)"
      ],
      "metadata": {
        "id": "OdEPHREURjnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of absent files in train 371')\n",
        "print('Number of absent files in test 58')\n",
        "print(f\"Number of Images absent in dataset {len(os.listdir('/content/drive/MyDrive/Data/Steel/all/images'))}\")"
      ],
      "metadata": {
        "id": "Scgp7y4hVUkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Text Files"
      ],
      "metadata": {
        "id": "0mEWddZZZpMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from documentation:\n",
        "\n",
        "**Each segmentation label must have a minimum of 3 xy points**\n",
        "\n",
        "**Labels should start with 0**\n"
      ],
      "metadata": {
        "id": "ZHFzq8nhXabo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_txt_file(idx, path):\n",
        "  img_name = data['ImageId'].iloc[idx]\n",
        "  img_class = data['ClassId'].iloc[idx]\n",
        "  rle = data['EncodedPixels'].iloc[idx]\n",
        "  mask = rle2mask(rle)\n",
        "  contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  f = open(path + img_name[:-3] + 'txt', \"a\")\n",
        "  for pair in contours:\n",
        "    pair = pair.reshape(-1, 2)\n",
        "    if len(pair) > 2:\n",
        "      f.write(str(img_class) + ' ')\n",
        "      for x, y in pair:\n",
        "        x, y = x / 1600, y / 256\n",
        "        f.write(str(x) + ' ' + str(y) + ' ')\n",
        "      f.write('\\n')\n",
        "  f.write('\\n')\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "OkCPvV1k7NBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Data/Steel/data/train/labels/'\n",
        "val_path = '/content/drive/MyDrive/Data/Steel/data/val/labels/'\n",
        "\n",
        "# existed_train = set()\n",
        "# existed_val = set()\n",
        "\n",
        "# train_all_img = os.listdir('/content/drive/MyDrive/Data/Steel/data/train/images/')\n",
        "# val_all_img = os.listdir('/content/drive/MyDrive/Data/Steel/data/val/images/')\n",
        "\n",
        "# for img_name in train_all_img:\n",
        "#     if img_name not in existed_train:\n",
        "#         existed_train.add(img_name)\n",
        "#         for idx in data.groupby(data.ImageId).get_group(img_name).index:\n",
        "#             create_txt_file(idx, train_path)\n",
        "# for img_name in val_all_img:\n",
        "#     if img_name not in existed_val:\n",
        "#         existed_val.add(img_name)\n",
        "#         for idx in data.groupby(data.ImageId).get_group(img_name).index:\n",
        "#             create_txt_file(idx, val_path)"
      ],
      "metadata": {
        "id": "P47VilixZseW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(os.listdir(val_path)) == len(os.listdir('/content/drive/MyDrive/Data/Steel/data/val/images'))\n",
        "assert len(os.listdir(train_path)) == len(os.listdir('/content/drive/MyDrive/Data/Steel/data/train/images'))"
      ],
      "metadata": {
        "id": "kDROyUqff2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create YAML-file"
      ],
      "metadata": {
        "id": "e3l17nX1gPlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data =  dict(\n",
        "    train = '/content/drive/MyDrive/Data/Steel/data/train/images',\n",
        "    val =  '/content/drive/MyDrive/Data/Steel/data/val/images',\n",
        "    nc = 4,\n",
        "    names = ['0', '1', '2', '3']\n",
        "            )\n",
        "with open('parameters.yaml', 'w') as outfile:\n",
        "    yaml.dump(data, outfile, default_flow_style=False)"
      ],
      "metadata": {
        "id": "nbxrANggyleb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "NbzOuFKSrXTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir path/to/runs"
      ],
      "metadata": {
        "id": "989jzeT91fxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8m-seg.pt')\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "KuqVuj-crYj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data='parameters.yaml', epochs=30)"
      ],
      "metadata": {
        "id": "-mkxPB3wxLnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**box_loss** shows the amount of error in detected bounding boxes.\n",
        "\n",
        "**cls_loss** shows the amount of error in detected object classes.\n",
        "\n",
        "**seg_loss** shows the amount of error in detected segmentation masks\n",
        "\n",
        "***DFL*** contribution to Bbox loss: Distance-IoU (DIoU) and Complete IoU (CIOU) are relatively recent adaptions to traditional Intersection over Union (IoU) loss used in the YOLOv3, and Directional Feature Learning (DFL) is the method used to train them. When DFL is applied to CIOU, we call it DFL-CIOU. DFL provides gradients that can guide the learning of boundary predicted features, thus helping to reduce the bbox loss.\n",
        "Decrease in DFL: If DFL decreases during training, it means the model is getting better at predicting the boundary box for your target detection task. The underlying reason for this decrease is indeed that the difference (or \"loss\") between the ground truth bounding boxes and the model's predicted bounding boxes is reducing over time.\n",
        "\n",
        "\n",
        "Why the loss split to several metrics? Because the model could correctly detect the bounding box around the object, but incorrectly detect the object class in this box. For example, in my practice, it detected the dog as a horse, but the dimensions of the object were detected correctly."
      ],
      "metadata": {
        "id": "GXxMUwenGMkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Mean Average Precision (mAP)?\n",
        "\n",
        "mAP formula is based on the following sub metrics:\n",
        "\n",
        "- Confusion Matrix,\n",
        "- Intersection over Union(IoU),\n",
        "- Recall,\n",
        "-\n",
        "\n",
        "Here is a summary of the steps to calculate the AP:\n",
        "\n",
        "1. Generate the prediction scores using the model.\n",
        "2. Convert the prediction scores to class labels.\n",
        "3. Calculate the confusion matrix—TP, FP, TN, FN.\n",
        "4. Calculate the precision and recall metrics.\n",
        "5. Calculate the area under the precision-recall curve.\n",
        "6. Measure the average precision.\n",
        "\n"
      ],
      "metadata": {
        "id": "YAzX93oDHFKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Weights"
      ],
      "metadata": {
        "id": "zhWmfKThWX2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sourse_dir = '/content/runs/segment/train3/weights/best.pt'\n",
        "dest_dir = '/content/drive/MyDrive/Models/yolo_steel.pt'\n",
        "shutil.copy(sourse_dir, dest_dir)"
      ],
      "metadata": {
        "id": "_yfIxKl6WXhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "dNii_LazOaF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = '/content/runs/segment/train3/confusion_matrix.png'\n",
        "img = cv2.imread(m)\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NykoTi_QXjn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = pd.read_csv('/content/runs/segment/train3/results.csv')\n",
        "r.head()"
      ],
      "metadata": {
        "id": "ZTlEGo-PZa9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(1, 1), edgecolor = (0.0, 0.0, 0.0, 0.0))\n",
        "fig.suptitle(\"Precision and Recal Rise though Traing\")\n",
        "sns.relplot(data=r, x=r.iloc[:, 0], y=r.iloc[:, 5])\n",
        "sns.relplot(data=r, x=r.iloc[:, 0], y=r.iloc[:, 6])"
      ],
      "metadata": {
        "id": "LLxYf9hyZrEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbscYV1aUuRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}